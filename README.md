<h1 align="center">SAPA Project by C242-PS212 Team </h1>
<p align="center">"Sign Language Personal Assistant"</p>

# Backgrounder

<img width="1114" height="625" alt="image" src="https://github.com/user-attachments/assets/a989545f-e664-4878-a7ce-235be38e6010" />


Indonesia has over 923,941 individuals who are deaf or hard of hearing, often facing communication chalenges, especialy with those who do not understand sign language. Our team's experience interacting with a deaf food vendor highlighted the communication barriers caused by a lack of understanding of sign language. This issue demonstrates the need for a solution to bridge the communication gap between both parties. Our project aims to develop a video processing application that can recognize sign language and translate it into Indonesian, facilitating interaction between the deaf community and the general public.

The application we developed, SAPA (Sign Language Personal Assistant), has two main features: sign language recognition and translation into Indonesian. Using advanced video processing technology, the app captures and interprets sign language gestures in real-time and translates them into Indonesian. With a user-friendly interface, SAPA is designed to facilitate communication between deaf individuals and those who do not understand sign language, ensuring accessibility for the entire community. SAPA is expected to improve interaction and understanding between the deaf community and the general public.Detailed works on each learning path include:
1. Machine Learning: building models with TensorFlow lite and TensorFlow. Js, using data pipeline to serve the models, and preprocess the data using Missing Values Imputation.
2. Mobile Development: Deployment of TensorFlow lite and creation of both a user and an admin app. The application has a real-time connection using Firebase and a mechanism to adatabufferincaseaninternet connection is unavailable.
3. Cloud Computing: Implementing a REST API with Node.js for profile management and user authentication using Firebase Authentication. User data is stored in Firestore, and the app is deployed on Cloud Run. Google Cloud Storage is used for storing ML models, with access controled through Service Accounts.

# Important Links
- Screenshots/demo video: https://drive.google.com/drive/folders/1x_FMPNB8TomKzzd0Uz72-4pXqSN2UuNg?usp=sharing
- Dataset Link: https://drive.google.com/drive/folders/1u4h5czEuaMrKDWpd5Kp5Ao6ki-CP3HFC?usp=sharing
- Deployed Link: https://drive.google.com/drive/folders/1-ri5tBwhzNgKsccmprZW-LdpY9ox-Qe8?usp=sharing
- Video presentation link: https://drive.google.com/drive/folders/1IJPRFJyD43nHG69vUWdlAJofKP-hnhMg?usp=sharing
- Slide presentation link: https://drive.google.com/file/d/1UEhY2rJkdAggxJStS1lv6u3ts2AYpSJn/view?usp=sharing
